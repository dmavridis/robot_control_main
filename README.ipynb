{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Presentation: ROS basics \n",
    "\n",
    "The purpose of this report is to demonstate, both in simulation and in a real robot, the use of ROS platform to navigate a robot in a predefined enviroment which consists of four walls. The robot, in general, has to move along the walls. Apart from the navigation itself, a service and an action node are developed.  \n",
    "\n",
    "## Package information\n",
    "\n",
    "**Name:** robot_control_main\n",
    "\n",
    "\n",
    "\n",
    "### Running in Simulation mode\n",
    "To run the simulation the following commands are necessary. \n",
    "\n",
    "**Shell #1**\n",
    "```\n",
    "roslaunch realrobotlab main.launch\n",
    "```\n",
    "\n",
    "**Shell #2**\n",
    "```\n",
    "roslaunch robot_control_main main.launch\n",
    "```\n",
    "\n",
    "(Optional) It will be helpful to use the teleop control for initially positioning the robot\n",
    "\n",
    "**Shell #3**\n",
    "```\n",
    "roslaunch turtlebot3_teleop turtlebot3_teleop_key.launch\n",
    "```\n",
    "\n",
    "**Make sure to interrupt the remote control while running the main node!!!**\n",
    "\n",
    "### Running in RobotLab\n",
    "As soon as the enviroment is loaded, use only the same command to launch the program, and/or the teleop control. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robot behaviour\n",
    "The robot itself is a **Turtebot3** one and a screenshot of the enviroment is shown below:\n",
    "\n",
    "<img src=\"new_sim.png\"/>\n",
    "\n",
    "\n",
    "The robot should apply the following **general behaviour**, in chronological order:\n",
    "- The robot from its starting position should move to the closest wall\n",
    "- The robot will navigate in parallel to the wall\n",
    "- When the robot completes one lap, it should stop and return the list of odometries recorded\n",
    "\n",
    "In more detail, there are some further requirements and specifications that are explained analytically in the specific sections.\n",
    "\n",
    "\n",
    "## Approach to the solution\n",
    "The code structure consists of 8 python files. 3 are used for interacting with the topics, 1 for the findwall service server, 1 for the odometry action server and 1 is the main behaviour node. A config file defines all the parameters and an extra postprocessing is proving a graph of the orbit. \n",
    "\n",
    "### Topics\n",
    "There are three topics in total required for the control of the robot and the feedback from the enviroment:\n",
    "- **/cmd_vel**: A publisher node that controls the movement of the robot. Values are assigned to the *linear.x* and *angular.z* parts  \n",
    "- **/scan**: A subscriber to the laser scanning of the enviroment, showing distance to obstacles in a 360 size array. Front is at index 180 and left and right at 90 and 270 respectively. \n",
    "- **/odom**: A subscriber that shows the position of the robot. It is only used in the action that measure the covered distance. \n",
    "\n",
    "The following three files define objects and functions to the mentioned topics:\n",
    "- **cmd_vel_publisher.py**: Defines the object **CmdVelPub** with main fuction:\n",
    "    - move_robot( direction, linearspeed=0.0, angularspeed=0.0): Moves robot to a direction with specific speed values\n",
    "- **laser_subscriber.py**: Defines the object **LaserTopicReader** with main fuction:\n",
    "  - wall_detector ( ): Returns three reading values, for the front, left and right directions\n",
    "- **odom_subscriber.py**: Defines the object **OdomTopicReader** with main fuction:\n",
    "  - wall_detector ( ): Returns three reading values, for the front, left and right directions\n",
    "\n",
    "### Nodes\n",
    "Since there three distinct parts of the behaviour, three nodes are defined.\n",
    "- **find_wall_service_server.py**: Defines the service */find_wall* that when called positions the robot in a predefined initial position\n",
    "- **record_odom_action_server.py**: Defines the */record_odom* topic as an action \n",
    "- **main_program.py**: The top level program that defines the *robot_control_main_node* and performs the specified behaviour.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "![rosgraph](rosgraph.png)\n",
    "\n",
    "\n",
    "\n",
    "### Launch\n",
    "In the launch file, the service and action servers are launched and then the main program executes as shown in the code:\n",
    "\n",
    "**main.launch**\n",
    "\n",
    "```\n",
    "<launch>\n",
    "<node pkg =\"robot_control_main\"\n",
    "    type=\"record_odom_action_server.py\"\n",
    "    name=\"record_odom_action_server_node\"\n",
    "    output=\"screen\">\n",
    "</node>\n",
    "\n",
    "<node pkg =\"robot_control_main\"\n",
    "    type=\"find_wall_service_server.py\"\n",
    "    name=\"find_wall_node\"\n",
    "    output=\"screen\">\n",
    "</node>\n",
    "\n",
    "<node pkg =\"robot_control_main\"\n",
    "    type=\"main_program.py\"\n",
    "    name=\"robot_control_main_node\"\n",
    "    output=\"screen\">\n",
    "</node>\n",
    "\n",
    "</launch>\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "## Starting position service\n",
    "The **find_wall** service takes an Empty input and returns the boolean *wallfound*. \n",
    "\n",
    "### Detailed behaviour for initial positioning\n",
    "The robot is initially at an arbirtrary position and has to reposition itself according to the following sequence:\n",
    "- Turn around to face the closest wall (Rotation #1)\n",
    "- Move forward to a distance of 0.3m from the wall (Positioning)\n",
    "- Turn around 90 degrees to have the wall on the right side (Rotation #2)\n",
    "\n",
    "In the code two variables are used to check for the progress and the completion of the service, *rotated* and *positioned* and start at False.\n",
    "\n",
    "- **Rotation 1**: Robot rurns around till the laser scan at front (index 180) has the minimum value. When done, **rotated = True**\n",
    "- **Positioning**: Robot moves till laser reading of front is <= 0.3m.  When done, **positioned = True, rotated = False**\n",
    "- **Rotation 2**: Robot turns 90 degrees laser scan at right has minimum value. When done, **positioned = True, rotated = True**\n",
    "\n",
    "Then the service completes and **wallfound=True**\n",
    "\n",
    "### Note\n",
    "The robot does not have advanced intelligence therefore when an obstacle is detected, it is considered to be a wall. Since the environment can have some other objects we need to make sure they stay away from the wall in order not to interfere with the robot. \n",
    "\n",
    "\n",
    "## Navigation node\n",
    "Once positioned and receiving the **wallfound** message, the robot starts moving in parallel the closest wall. It constantly reads the front and right distances with the laser sensor and adapts the angular speed to avoid wall at the front and to keep a constant distance from the right side.  \n",
    "\n",
    "The wall following behavior is a behavior that makes the robot follow along the wall on its right hand side. This means that the robot must be moving forward at a 30cm (1 foot) distance from the wall, having the wall on its right hand side, the entire time.\n",
    "- If the ray distance is bigger than 0.3m, you need to make the robot approach the wall a little, by adding some rotational speed to the robot\n",
    "- If the ray distance is lower than 0.2m, you need to move the robot away from the wall, by adding rotational speed in the opposite direction\n",
    "- If the ray distance is between 0.2m and 0.3m, just keep the robot moving forward\n",
    "\n",
    "The behaviour is implemented in the main node and continues till it completes a lap, a signal that is sent by the odometry action.\n",
    "\n",
    "    \n",
    "## Odometry action\n",
    "\n",
    "The odometry action start with the navigation node. It has no goal but it is considered complete when the robot is close to its initial position after completing a lap. To do so, when the node start the initial pose is captured and there is always a check to see how close its current position is to the initial one. \n",
    "\n",
    "To avoid sending a success signal early, we consider that the robot has to move at least 1m from its initial position. Additionally, to avoid missing the target after the lap, a radius of 0.25m around the initial position is considered a margin. If by any chance the robot fails to pass closer to that distance, after 10m it will stop nevertheless. \n",
    "\n",
    "As a feedback the robot returns the distance covered so far. At a rate of 1sec, the linear distance between two successive points is added to the total one. \n",
    "\n",
    "The result after the action is finished, is an array of the points the robot's orbit.\n",
    "\n",
    "Once action is complete, the robot stops and its mission is accomplished. \n",
    "\n",
    "\n",
    "    \n",
    "## Results\n",
    "\n",
    "The code is tested both in simulation and the real robot and the results are shown in the following videos.\n",
    "\n",
    "### Testing the package in simulation environment\n",
    "\n",
    "[![RobotX](http://img.youtube.com/vi/ZoI2RdrBV6Y/0.jpg)](https://youtu.be/ZoI2RdrBV6Y \"RobotX\")\n",
    "\n",
    "### Testing the package in Real Robot\n",
    "\n",
    "[![RobotX](http://img.youtube.com/vi/vXqvZJl8p2o/0.jpg)](https://youtu.be/vXqvZJl8p2o \"RobotX\")\n",
    "\n",
    "### Orbit from the action\n",
    "To demonstrate that the action returns the correct results, the points are plotted as shown below and this behaviour is the expected one. \n",
    "![orbit](orbit.png)\n",
    "\n",
    "\n",
    "## Improvements\n",
    "After the initial development of the solution and observation of the behaviour there are some points of improvement. Mainly, the navigation can be a bit more elaborated from a fixed linear and angular speed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
